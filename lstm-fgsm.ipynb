{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QMwzaCKCsMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tutorial: https://github.com/bentrevett/pytorch-sentiment-analysis\n",
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-rdR6IxK60w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Include length for packed padded sequence\n",
        "text = data.Field(tokenize='spacy', include_lengths=True)\n",
        "label = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IfOxn0yDzUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d687a9c8-64ba-47ae-b706-ae91d0febf39"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(text, label)\n",
        "\n",
        "import random\n",
        "train_data, val_data = train_data.split(random_state=random.seed(SEED))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 197k/84.1M [00:00<00:49, 1.69MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 67.4MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTjud7lSGOOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "841f41f7-1846-4494-cf99-c6cd1cb09195"
      },
      "source": [
        "# Use pretrained Embeddings\n",
        "VOCAB_SIZE = 25000\n",
        "\n",
        "# Vocab is lookup table for every word\n",
        "text.build_vocab(train_data,\n",
        "                 max_size = VOCAB_SIZE,\n",
        "                 vectors = 'glove.6B.100d',\n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "label.build_vocab(train_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:26, 2.23MB/s]                           \n",
            "100%|█████████▉| 399506/400000 [00:22<00:00, 18606.47it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9ETu3_NMh-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "device = torch.device(\n",
        "            'cuda' if torch.cuda.is_available()\n",
        "            else 'cpu')\n",
        "\n",
        "train_iterator, \\\n",
        "val_iterator, \\\n",
        "test_iterator = data.BucketIterator.splits(\n",
        "                    (train_data, val_data, test_data),\n",
        "                    batch_size = batch_size,\n",
        "                    sort_within_batch = True,\n",
        "                    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyBjDK7AOWUI",
        "colab_type": "text"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KtrXH7hOXSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                 num_layers, is_bidirectional, dropout_rate, padding_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim,\n",
        "                                      padding_idx = padding_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                          num_layers = num_layers,\n",
        "                          bidirectional = is_bidirectional,\n",
        "                          dropout = dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        # Pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        self.rnn.flatten_parameters()\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "        # Unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))\n",
        "\n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX-DU8cQfwpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(text.vocab)\n",
        "embedding_dim = 100 # Should be same as dim of pre trained embeddings\n",
        "hidden_dim = 256\n",
        "output_dim = 1\n",
        "num_layers = 2\n",
        "is_bidirectional = True\n",
        "dropout_rate = 0.5\n",
        "pad_idx = text.vocab.stoi[text.pad_token]\n",
        "\n",
        "\n",
        "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim,\n",
        "            num_layers, is_bidirectional, dropout_rate, pad_idx)\n",
        "\n",
        "pretrained_embeddings = text.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "# Zero <unk> and <pad> embeddings which are prior initailized using unk_init\n",
        "unk_idx = text.vocab.stoi[text.unk_token]\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HbGUFsJkx1k",
        "colab_type": "code",
        "outputId": "ec2c3748-16c0-44ad-c787-692f99e3bb95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
            "        ...,\n",
            "        [-0.3943,  0.2772,  1.1245,  ..., -0.0325, -0.3586,  0.3960],\n",
            "        [ 0.0625,  0.0986,  1.2180,  ..., -0.2652,  0.0377,  0.2616],\n",
            "        [ 0.1403, -0.1464,  0.4232,  ...,  0.6345, -0.2789, -0.4798]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA0kJC-JgavE",
        "colab_type": "code",
        "outputId": "05e8d346-812b-4bed-ead8-bf86ec98635d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4810857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwusZiWegiR4",
        "colab_type": "code",
        "outputId": "4f4611be-17fe-4f1c-975e-6efd01e202b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RNN(\n",
            "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
            "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPp3vXzVk52E",
        "colab_type": "text"
      },
      "source": [
        "# Define Train and Eval functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nSWHRDsjCp8",
        "colab_type": "code",
        "outputId": "99e4f7e1-2840-42fa-aab3-90450fb196b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model.to(device)\n",
        "criterion.to(device)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r100%|█████████▉| 399506/400000 [00:40<00:00, 18606.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfRfePKMlQy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(y_pred, y_orig):\n",
        "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "    correct = (y_pred == y_orig).float()\n",
        "    accuracy = correct.sum() / len(correct)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnwiBNT4lmFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    for data in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text, text_lengths = data.text\n",
        "        \n",
        "        y_pred = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(y_pred, data.label)\n",
        "        acc = accuracy(y_pred, data.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    \n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTFXnz3wmqS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in iterator:\n",
        "            text, text_lengths = data.text\n",
        "\n",
        "            y_pred = model(text, text_lengths).squeeze(1)\n",
        "            loss = criterion(y_pred, data.label)\n",
        "            acc = accuracy(y_pred, data.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9sWheGBnawg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "def epoch_time(s, e):\n",
        "    diff = e - s\n",
        "    diff_min = int(diff / 60)\n",
        "    diff_sec = int(diff - (diff_min * 60))\n",
        "\n",
        "    return diff_min, diff_sec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1spZX3zZnvN4",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP42BM1ant2Y",
        "colab_type": "code",
        "outputId": "b2c454ef-93b5-428f-ea52-55eecb226140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "epochs = 5\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    val_loss, val_acc = evaluate(model, val_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_min, epoch_sec = epoch_time(start_time, end_time)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), 'senti-lstm.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_min}m {epoch_sec}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f} |  Val. Acc: {val_acc*100:.2f}%')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 1m 41s\n",
            "\tTrain Loss: 0.668 | Train Acc: 58.54%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 58.26%\n",
            "Epoch: 02 | Epoch Time: 1m 41s\n",
            "\tTrain Loss: 0.640 | Train Acc: 63.05%\n",
            "\t Val. Loss: 0.648 |  Val. Acc: 65.14%\n",
            "Epoch: 03 | Epoch Time: 1m 41s\n",
            "\tTrain Loss: 0.563 | Train Acc: 71.37%\n",
            "\t Val. Loss: 0.431 |  Val. Acc: 80.54%\n",
            "Epoch: 04 | Epoch Time: 1m 41s\n",
            "\tTrain Loss: 0.424 | Train Acc: 81.32%\n",
            "\t Val. Loss: 0.365 |  Val. Acc: 85.68%\n",
            "Epoch: 05 | Epoch Time: 1m 41s\n",
            "\tTrain Loss: 0.322 | Train Acc: 86.80%\n",
            "\t Val. Loss: 0.303 |  Val. Acc: 87.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4W6DD_9raqo",
        "colab_type": "text"
      },
      "source": [
        "# Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxznO9Sko-wg",
        "colab_type": "code",
        "outputId": "d90bcfef-7be5-40ce-b61d-99a28a961fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('senti-lstm.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.307 | Test Acc: 87.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKcMXmWVrcNE",
        "colab_type": "text"
      },
      "source": [
        "# Run model on user input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_s-z0rUrZGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_senti(model, sentence):\n",
        "    model.eval()\n",
        "\n",
        "    tokenized = [token.text for token in nlp.tokenizer(sentence)]\n",
        "    indexed = [text.vocab.stoi[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "\n",
        "    y_pred = torch.sigmoid(model(tensor, length_tensor))\n",
        "\n",
        "    return y_pred.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtf9bn4EuUmo",
        "colab_type": "code",
        "outputId": "65a4da31-83c6-4a90-cbb2-258ba11c7869",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "sentences = [\n",
        "    'This movies is alright',\n",
        "    'Pathetic hero. Anyways, the movie is good',\n",
        "    'Wasted my money on this film',\n",
        "    'The movie is not good, its amazing',\n",
        "    'The movie is not good',\n",
        "    'The movie is bad',\n",
        "    'Read the book, forget the movie!',\n",
        "    \"This is a good film. This is very funny. Yet after this film there were no good Ernest films!\",\n",
        "\n",
        "]\n",
        "\n",
        "for sentence in sentences:\n",
        "    print(sentence, predict_senti(model, sentence))\n",
        "\n",
        "'''\n",
        "This movies is alright 0.047230374068021774\n",
        "Pathetic hero. Anyways, the movie is good 0.9136135578155518\n",
        "Wasted my money on this film 0.04066199064254761\n",
        "The movie is not good, its amazing 0.9808578491210938\n",
        "The movie is not good 0.9080145359039307\n",
        "The movie is bad 0.022998275235295296\n",
        "Read the book, forget the movie! 0.9118732213973999\n",
        "This is a good film. This is very funny. Yet after this film there were no good Ernest films! 0.5877493023872375\n",
        "'''"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This movies is alright 0.047230374068021774\n",
            "Pathetic hero. Anyways, the movie is good 0.9136135578155518\n",
            "Wasted my money on this film 0.04066199064254761\n",
            "The movie is not good, its amazing 0.9808578491210938\n",
            "The movie is not good 0.9080145359039307\n",
            "The movie is bad 0.022998275235295296\n",
            "Read the book, forget the movie! 0.9118732213973999\n",
            "This is a good film. This is very funny. Yet after this film there were no good Ernest films! 0.5877493023872375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThis movies is alright 0.019804159179329872\\nPathetic hero. Anyways, the movie is good 0.5108079314231873\\nWasted my money on this film 0.02908250130712986\\nThe movie is not good, its amazing 0.9804919958114624\\nThe movie is not good 0.9206928014755249\\nThe movie is bad 0.09977895766496658\\nRead the book, forget the movie! 0.9224293828010559\\nThis is a good film. This is very funny. Yet after this film there were no good Ernest films! 0.9840355515480042\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73vJcAA1feCc",
        "colab_type": "text"
      },
      "source": [
        "# Gradient experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWRg2BU8H1oc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# distance metric: L2\n",
        "def nearest_neighbour(embeddings, source):\n",
        "    return \\\n",
        "    torch.argmin(torch.sum(torch.pow(embeddings - source,2), 1)).item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7KcJUUakXM8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "bd24fd0e-b5c7-449e-f1e3-7dd4dfce0227"
      },
      "source": [
        "import copy\n",
        "saved_model = copy.deepcopy(model)\n",
        "saved_model.eval()\n",
        "saved_model.to(device)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(25002, 100, padding_idx=1)\n",
              "  (rnn): LSTM(100, 256, num_layers=2, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU_il_O5LqwQ",
        "colab_type": "text"
      },
      "source": [
        "# FGSM using learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Erlp_afLuDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "709af4bc-1da7-4e37-f0fa-503912d78cf5"
      },
      "source": [
        "i = 0\n",
        "\n",
        "embeddings = saved_model.embedding.weight.data\n",
        "for batch in test_iterator:\n",
        "    b_sentences, b_lengths = batch.text\n",
        "    b_labels = batch.label\n",
        "\n",
        "    if i == 1:\n",
        "        break\n",
        "    else:\n",
        "        i += 1\n",
        "\n",
        "    epsilons = [.51]\n",
        "    for epsilon in epsilons:\n",
        "        num_evaded = 0\n",
        "        print(epsilon, \"\\n===\\n\")\n",
        "        for idx in range(batch_size):\n",
        "            sentences, length = b_sentences[:, idx].unsqueeze(1), b_lengths[idx].unsqueeze(0)\n",
        "            label = b_labels[idx].unsqueeze(0)\n",
        "    \n",
        "\n",
        "            # RNN needs to be in train() to calculate gradient\n",
        "            # Hence, disable dropouts manually\n",
        "            model.train()\n",
        "            model.embedding.weight.requires_grad = True\n",
        "            for name, module in model.named_modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "        \n",
        "                elif isinstance(module, nn.LSTM):\n",
        "                    module.dropout = 0\n",
        "        \n",
        "                elif isinstance(module, nn.GRU):\n",
        "                    module.dropout = 0\n",
        "        \n",
        "            pred = saved_model(sentences, length).squeeze(1)\n",
        "            y_pred = model(sentences, length).squeeze(1)\n",
        "        \n",
        "            if torch.round(torch.sigmoid(pred)).item() != label.item():\n",
        "                continue\n",
        "        \n",
        "            loss = criterion(y_pred, label)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "        \n",
        "            data_grad = model.embedding.weight.grad.data\n",
        "        \n",
        "            tmp_sen = sentences.clone()\n",
        "            # FGSM\n",
        "            updated_embed = embeddings + epsilon*data_grad.sign()\n",
        "            \n",
        "            for idx, t in enumerate(sentences):\n",
        "                # up_pre = nearest_neighbour(updated_embed, updated_embed[t])\n",
        "                # up_new = nearest_neighbour(updated_embed, embeddings[t])\n",
        "\n",
        "                up_prev = nearest_neighbour(embeddings, embeddings[t])\n",
        "                up_new = nearest_neighbour(embeddings, updated_embed[t])        \n",
        "\n",
        "                if t == pad_idx or t == unk_idx:\n",
        "                    continue\n",
        "                tmp_sen[idx] = up_new\n",
        "            \n",
        "            adv_pred = model(tmp_sen, length).squeeze(1)\n",
        "            main_pred = saved_model(tmp_sen, length).squeeze(1)\n",
        "            if torch.round(torch.sigmoid(main_pred)).item() != label.item():\n",
        "                num_evaded += 1\n",
        "                print(\"OG: \", label.item(), \", y_pred: \", torch.round(torch.sigmoid(y_pred)).item(), \" adv_pred: \", torch.round(torch.sigmoid(adv_pred)).item())\n",
        "                print(\"> RL: \", end='')\n",
        "                for t in sentences:\n",
        "                    print(text.vocab.itos[t], end=' ')\n",
        "                print(torch.sigmoid(y_pred).item(), end=\", \")\n",
        "                print(torch.sigmoid(pred).item())\n",
        "        \n",
        "                print(\"- ADV: \", end='')\n",
        "                for t in tmp_sen:\n",
        "                    print(text.vocab.itos[t], end=' ')\n",
        "                print(torch.sigmoid(adv_pred).item(), end=\", \")\n",
        "                print(torch.sigmoid(main_pred).item())\n",
        "        \n",
        "                print(\"------------------\")\n",
        "        print(\"Number of evasions: \", num_evaded)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.51 \n",
            "===\n",
            "\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: What a stinker ! ! ! I swear this movie was written by a computer that took a whole pile of other movies and <unk> them all together into this <unk> of film . <unk> ! 0.02763589657843113, 0.02763589657843113\n",
            "- ADV: What a shocker ! ! ! I swear it movie also written by a computer that took a whole piles of those movies well <unk> them today together into it <unk> of film today <unk> ! 0.7065791487693787, 0.7065791487693787\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: Well , this movie actually did have one redeeming quality . It made up the funniest season one episode of <unk> I wish <unk> had released this one instead of \" The <unk> Hand . \" 0.30906128883361816, 0.30906128883361816\n",
            "- ADV: Well , it movie actually did have today redeeming quality well It also up the funniest season today episode of <unk> I wish <unk> had released it today then of \" The <unk> Hand well \" 0.956963300704956, 0.956963300704956\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I 've seen soap operas more intelligent than this movie . Bad characters , bad story and bad acting . It would be a love story between a man and a mermaid . Really awful . 0.01795487105846405, 0.01795487105846405\n",
            "- ADV: I 've seen soap operas more intelligent than it movie . Bad characters , things story and things acting . It will be a love story between a man and a mermaid . Really things . 0.9692224860191345, 0.9692224860191345\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I had to see this on the British <unk> plane . It was terribly bad acting and a dumb story . Not even a kid would enjoy this . Something to switch off if possible . 0.018805403262376785, 0.018805403262376785\n",
            "- ADV: I had to see it on the British <unk> plane . It later definitely things acting but a smart story . Not now a kid will enjoy it . Something to switch off if possible . 0.9238121509552002, 0.9238121509552002\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: John Leguizamo 's \" <unk> \" is one of the funniest one - man shows I 've ever seen ! I recommend it to anyone ! Well , anyone with a good sense of humor .... 0.9451526403427124, 0.9451526403427124\n",
            "- ADV: John Leguizamo 's \" <unk> \" only only of the funniest only - man show I 've could seen ! I recommend not to else ! Well , else with a n't much of humor .... 0.09646962583065033, 0.09646962583065033\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This movie is based on the novel Island of <unk> . Moreau By H.G. Wells . It 's a fairly good one too , it 's at least better than the version by John Frankenheimer . 0.8145580291748047, 0.8145580291748047\n",
            "- ADV: This movie be based on the novel Island of <unk> because Moreau By H.G. Wells because It 's a poorly n't only nothing , not 's at least worse than the version by John Frankenheimer because 0.009842966683208942, 0.009842966683208942\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: I do n't believe it ... Luc <unk> is not only a genius now ... he has always been one ... this film is for everyone who likes real good deep films ... just perfect ! 0.9519896507263184, 0.9519896507263184\n",
            "- ADV: I do nothing nothing but nothing Luc <unk> only nothing no a genius not nothing not has not been only nothing nothing film only for why who likes real n't deep films nothing nothing same ! 0.01709868013858795, 0.01709868013858795\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: 1st watched <unk> - ( Dir - Tim Robbins ) : Very thought provoking and very well done movie on the subject of the death penalty . <unk> more recognition and publicity than it received . 0.9427893757820129, 0.9427893757820129\n",
            "- ADV: 1st watched <unk> - ( Dir - Tim Robbins ) : Very why fearing . not . doing movie on the subject of the death penalty because <unk> than recognition . publicity than not received because 0.056818000972270966, 0.056818000972270966\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: a real hoot , unintentionally . <unk> <unk> 's character is so sweet and lovable you want to smack him . nothing about this movie rings true . and it 's boring to boot . <pad> 0.029267268255352974, 0.029267268255352974\n",
            "- ADV: a real hoot , inadvertently . <unk> <unk> 's character is it sweet and endearing you want to smack him . something about it movie rings true . and it 's unlike to boot . <pad> 0.9645733833312988, 0.9645733833312988\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Complete entertainment ! Although there are many strange things in the movie that the fairy tale itself does n't have them including the autumn characters ( mother and daughter ) the general concept rocks . <pad> 0.8546915054321289, 0.8546915054321289\n",
            "- ADV: Complete entertainment ! Although no are some bizarre nothing in the movie not the fairy tale itself instead nothing have instead including the autumn characters ( mother . wife ) the general idea rocks because <pad> 0.020278606563806534, 0.020278606563806534\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: If you are French native , then you find this movie extremely funny . It 's good , just good ! Can though imagine that subtitles or <unk> do n't mean much in english . <pad> 0.8418493866920471, 0.8418493866920471\n",
            "- ADV: If n't are French native , instead n't enough only movie extremely joke because It 's n't , nothing n't ! Can because nothing that subtitles or <unk> n't bad awful nothing in english because <pad> 0.013437525369226933, 0.013437525369226933\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Wonderful movie . Adult content . Lots of erotic scenes plus excellent music and dance scenes . My wife and I absolutely loved this movie and wish they 'd make more like it . <pad> <pad> 0.9751803874969482, 0.9751803874969482\n",
            "- ADV: Wonderful movie because Adult content because Lots of erotic scenes plus solid music while dance scenes because My husband while I nothing others instead movie while not they nothing instead than like but because <pad> <pad> 0.051579538732767105, 0.051579538732767105\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: I see it when I was 12 year old and I dream to see it again ! < br /><br />What marvelous Sammy Davis Jr singing \" it ai n't necessarily so ! \" <pad> <pad> 0.951101541519165, 0.951101541519165\n",
            "- ADV: I do that because I was 4 last old while I idea to do that could ! < br /><br />What supposed Sammy Davis Jr singing \" that ai nothing necessarily because ! \" <pad> <pad> 0.05147743970155716, 0.05147743970155716\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The one - liners fly so fast in this movie that you can watch it over and over and still catch new ones . By far one of the best of this genre . <pad> <pad> 0.9486866593360901, 0.9486866593360901\n",
            "- ADV: The only - liners fly nothing slow in no movie could n't could watch that instead . instead . could catch new instead because By far only of could as of no genre because <pad> <pad> 0.017652440816164017, 0.017652440816164017\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This is a very cool movie . The ending of the movie is a bit more defined than the play 's ending , but either way it is still a good movie . <pad> <pad> <pad> 0.9901601672172546, 0.9901601672172546\n",
            "- ADV: This not a because cool movie because The instead of the movie not a much than defined than the play 's instead , no instead not not not could a not movie because <pad> <pad> <pad> 0.018752755597233772, 0.018752755597233772\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Great cast , great acting , great music . Each character in this movie had their own stories and personalities and it 's vivid . A great movie not to be missed . <pad> <pad> <pad> 0.9859220385551453, 0.9859220385551453\n",
            "- ADV: Great cast , what acting , what music because Each character in only movie had their own stories . personalities . not 's instead because A what movie nothing could not missed because <pad> <pad> <pad> 0.30938008427619934, 0.30938008427619934\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: Do n't waste your time and money on it . It 's not quite as bad as \" <unk> \" , by the same director but that 's not saying much . <pad> <pad> <pad> <pad> 0.010972707532346249, 0.010972707532346249\n",
            "- ADV: Do n't waste your time and money on it . It 's would quite as things as \" <unk> \" sure by today today director it that 's would told it . <pad> <pad> <pad> <pad> 0.5248491168022156, 0.5248491168022156\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The plot was really weak and confused . This is a true Oprah flick . ( In Oprah 's world , all men are evil and all women are victims . ) <pad> <pad> <pad> <pad> 0.32023176550865173, 0.32023176550865173\n",
            "- ADV: The plot was definitely strong and surprised and This is a true Oprah flick and ( In Oprah 's world and today men are evil and today women are victims and ) <pad> <pad> <pad> <pad> 0.9633876085281372, 0.9633876085281372\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Very intelligent language usage of Ali , which you <unk> miss ! In one word : ( <unk> sentence ... ) Wicked , so keep it real and pass it on ! <pad> <pad> <pad> <pad> 0.8696677088737488, 0.8696677088737488\n",
            "- ADV: Very intelligent language usage of Ali , which n't <unk> miss ! In only word : ( <unk> sentence nothing ) Wicked , instead instead not real . pass not on ! <pad> <pad> <pad> <pad> 0.12062100321054459, 0.12062100321054459\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: I really enjoyed this movie ... In My DVD collection of baseball movies ... <unk> me how great the sport truly is ... Whether it 's here in America or Japan . <pad> <pad> <pad> <pad> 0.9719303250312805, 0.9719303250312805\n",
            "- ADV: I n't having not movie nothing In My DVD collection of baseball movies nothing <unk> me why as the sport nothing is nothing Whether not 's here in America instead Japan because <pad> <pad> <pad> <pad> 0.020995154976844788, 0.020995154976844788\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: this was a get up and go horror movie with an intelligent cast and a director with great vision to really capture the mood of the story i highly recommend this movie <pad> <pad> <pad> <pad> 0.9715262055397034, 0.9715262055397034\n",
            "- ADV: not not a get up . go horror movie with an intelligent cast . a director with see vision to nothing capture only mood of only story n't highly recommend not movie <pad> <pad> <pad> <pad> 0.20683446526527405, 0.20683446526527405\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: As a big fan of Tiny <unk> Adventures , I loved this movie ! ! ! It was so funny ! ! ! It really captured how cartoons spent their <unk> . <pad> <pad> <pad> <pad> 0.9761292934417725, 0.9761292934417725\n",
            "- ADV: As a big fan of Tiny <unk> Adventures , I whom no movie ! ! ! It instead nothing joke ! ! ! It n't captured why cartoons spent their <unk> because <pad> <pad> <pad> <pad> 0.06272809207439423, 0.06272809207439423\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: This movie was so incredibly boring , Michael J. Fox could 've done so much better . Sorry , but it 's true for all you people who liked the movie <pad> <pad> <pad> <pad> <pad> 0.07427563518285751, 0.07427563518285751\n",
            "- ADV: This movie was well wonderful unlike , Michael J. Fox would i done well it good well Sorry , it it 's true for both you people who liked the movie <pad> <pad> <pad> <pad> <pad> 0.9906747937202454, 0.9906747937202454\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: You 've got to be kidding . This movie sucked for the sci - fi fans . I would only recommend watching this only if you think Armageddon was good . <pad> <pad> <pad> <pad> <pad> 0.1069076806306839, 0.1069076806306839\n",
            "- ADV: You 've got to will kidding and This movie shivers for the sci - fi fans and I will it recommend watching it it it you think Armageddon was excellent and <pad> <pad> <pad> <pad> <pad> 0.9646236300468445, 0.9646236300468445\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I caught this film late at night on HBO . Talk about wooden acting , unbelievable plot , et al . Very little going in its favor . Skip it . <pad> <pad> <pad> <pad> <pad> 0.03167211636900902, 0.03167211636900902\n",
            "- ADV: I caught it film late at night on HBO and Talk about wooden acting only incredible plot only et al and Very great think in its favor and Skip it and <pad> <pad> <pad> <pad> <pad> 0.7070030570030212, 0.7070030570030212\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The Buddy Holly Story is a great biography with a super performance from Gary Busey . Busey did his own singing for this film and he does a great job . <pad> <pad> <pad> <pad> <pad> 0.968884289264679, 0.968884289264679\n",
            "- ADV: The Buddy Holly Story is a as biography with a super performance from Gary Busey because Busey supposed his instead singing instead no film . he nothing a as job because <pad> <pad> <pad> <pad> <pad> 0.06988688558340073, 0.06988688558340073\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Anyone who gives this movie less than 8 needs to step outside & <unk> a couple . Great story.<br /><br <unk> is for people who ca n't handle drugs . <pad> <pad> <pad> <pad> <pad> <pad> 0.6964040994644165, 0.6964040994644165\n",
            "- ADV: Anyone who only no movie less than 6 instead to instead outside & <unk> a instead because Great story.<br /><br <unk> is for people who bad nothing handle drugs because <pad> <pad> <pad> <pad> <pad> <pad> 0.016427239403128624, 0.016427239403128624\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: <unk> Classic Waters ! One of his best and most shocking films ! Divine is THE most filthy person ever ! <unk> Stole also delivers a superb performance ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9886094331741333, 0.9886094331741333\n",
            "- ADV: <unk> Classic Waters ! One of his as they only embarrassing films ! Divine not THE only filthy person could ! <unk> Stole also instead only scoring performance ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.06250015646219254, 0.06250015646219254\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Great story , great music . A heartwarming love story that 's beautiful to watch and delightful to listen to . Too bad there is no soundtrack CD . <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9602134227752686, 0.9602134227752686\n",
            "- ADV: Great story , great music instead A heartwarming love story could 's just to go . clumsy to hear to instead Too awful there is no soundtrack CD instead <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.05414073169231415, 0.05414073169231415\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: If you 've ever had a mad week - end out with your mates then you 'll appreciate this film . Excellent fun and a laugh a minute . <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9522498846054077, 0.9522498846054077\n",
            "- ADV: If n't 've could had a mad last - instead instead with your mates instead n't 'll want no film because Excellent 'd . a joke a minute because <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.02017177641391754, 0.02017177641391754\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: A great film in its genre , the direction , acting , most especially the casting of the film makes it even more powerful . A must see . <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.987263023853302, 0.987263023853302\n",
            "- ADV: A come film in its genre , only direction , acting , some because only casting of only film does that nothing than powerful because A should not because <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.05029468983411789, 0.05029468983411789\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: Widow hires a psychopath as a <unk> . <unk> film noir thriller which does n't make much of its tension promising set - up . ( 3/10 ) <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.025677036494016647, 0.025677036494016647\n",
            "- ADV: Widow hires a psychopath well a <unk> and <unk> film noir thriller which does want will as of its tension future set - up and ( <pad> ) <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9354796409606934, 0.9354796409606934\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Without a doubt , one of Tobe <unk> 's best ! <unk> <unk> , great special effects , and The <unk> ( vamp me baby ! ) . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9570972323417664, 0.9570972323417664\n",
            "- ADV: Without only nothing , only of Tobe <unk> 's as ! <unk> <unk> , as special effects , . The <unk> ( vamp me baby ! ) because <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.04666253179311752, 0.04666253179311752\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The acrobatics mixed with haunting music , make one spectacular show . The costumes are vibrant and the performances will just <unk> your mind ! Simply amazing ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.981661856174469, 0.981661856174469\n",
            "- ADV: The acrobatics mixed with cartoonish music , instead only spectacular show not The costumes are vibrant . the performances would nothing <unk> your n't ! Simply amazing ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.24397936463356018, 0.24397936463356018\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Brilliant . <unk> along with Citizen Kane , The Matrix and <unk> . Must see , at least for <unk> in her early days . Watch it . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9114730358123779, 0.9114730358123779\n",
            "- ADV: Brilliant because <unk> along with Citizen Kane , The Matrix while <unk> because Must not , at least for <unk> in her early weeks because Watch only because <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.1948183923959732, 0.1948183923959732\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: This movie is terrible . It 's about some no brain <unk> dude that inherits some company . Does Carrot Top have no <unk> /><br / > <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.026180054992437363, 0.026180054992437363\n",
            "- ADV: This movie is tragedy well It 's about many . brain <unk> dude it inherits many company well Does Carrot Top have . <unk> /><br / > <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9816100597381592, 0.9816100597381592\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This is the greatest movie ever . If you have written it off with out ever seeing it . You must give it a second try . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9492371678352356, 0.9492371678352356\n",
            "- ADV: This that the greatest movie could because If n't have written not off with out could instead not because You should give not a third try because <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.11807131767272949, 0.11807131767272949\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: If you like <unk> Shore , you 'll love Son in Law . If you hate <unk> Shore , then , well ... I liked it ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9732288718223572, 0.9732288718223572\n",
            "- ADV: If n't like <unk> Shore , n't 'll love Son in Law only If n't hate <unk> Shore , instead , not nothing I why that ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.16704945266246796, 0.16704945266246796\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Absolutely fantastic ! Whatever I say would n't do this underrated movie the justice it deserves . Watch it now ! <unk> ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9543924927711487, 0.9543924927711487\n",
            "- ADV: Absolutely happened ! Whatever I nothing could n't do only overrated movie the justice not nothing only Watch not only ! <unk> ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.030801385641098022, 0.030801385641098022\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Add this little gem to your list of holiday regulars . It is < br /><br <unk> , funny , and endearing <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9833358526229858, 0.9833358526229858\n",
            "- ADV: Add not no diamond to your list of holiday regulars instead It is < br /><br <unk> , joke , and comical <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.03233572468161583, 0.03233572468161583\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This is a good film . This is very funny . Yet after this film there were no good Ernest films ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.5877493023872375, 0.5877493023872375\n",
            "- ADV: This be a n't film but This be not funny but Yet after this film nothing were no n't Ernest films ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.016978934407234192, 0.016978934407234192\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: One of the funniest movies made in recent years . Good characterization , plot and exceptional chemistry make this one a classic <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.98752361536026, 0.98752361536026\n",
            "- ADV: One of the funniest movies instead in recent months instead Good incoherent , plot . exceptional chemistry nothing no only a classic <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.03421785682439804, 0.03421785682439804\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: a mesmerizing film that certainly keeps your attention ... Ben Daniels is fascinating ( and courageous ) to watch . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9809313416481018, 0.9809313416481018\n",
            "- ADV: a cheerfully film could nothing keeps your attention nothing Ben Daniels is interesting ( . courageous ) could watching because <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.022907525300979614, 0.022907525300979614\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I hope this group of film - makers never re - <unk> . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.17263852059841156, 0.17263852059841156\n",
            "- ADV: I hope it group of film - makers always re - <unk> and <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.7727938890457153, 0.7727938890457153\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Brilliant and moving performances by Tom <unk> and Peter Finch . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9669718146324158, 0.9669718146324158\n",
            "- ADV: Brilliant they move performances by Tom <unk> they Peter Finch because <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.19068914651870728, 0.19068914651870728\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: <unk> <unk> <unk> interpretation . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.14224642515182495, 0.14224642515182495\n",
            "- ADV: <unk> <unk> <unk> interpretation today <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9362161159515381, 0.9362161159515381\n",
            "------------------\n",
            "Number of evasions:  46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDzX8_TLnQ0",
        "colab_type": "text"
      },
      "source": [
        "# FGSM using plain Glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUfsK5MpN8PM",
        "colab_type": "text"
      },
      "source": [
        "This shows what words are most important to the Neural network. For example:\n",
        "```\n",
        "> RL: I 've seen soap operas more intelligent than this movie . Bad characters , *bad* story and *bad* acting . It would be a love story between a man and a mermaid . Really *awful* . 0.01795487105846405, 0.01795487105846405\n",
        "- ADV: I 've seen soap operas more intelligent than this movie . Bad characters , *well* story and *well* acting . It would be a love story between a man and a mermaid . Really *wonderful* . 0.9766141772270203, 0.9766141772270203\n",
        "------------------\n",
        "```\n",
        "The Neural Net is heavily affected by the adjectives like _bad, awful, well, wonderful_ but this is not all. The \"bad\" associated with _characters_ is not changed, while other \"bad\"s are replaced by positive words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2lfILTmkGdE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c8444be-3874-4f96-c6d8-a8d3eafdc566"
      },
      "source": [
        "i = 0\n",
        "\n",
        "embeddings = pretrained_embeddings\n",
        "for batch in test_iterator:\n",
        "    b_sentences, b_lengths = batch.text\n",
        "    b_labels = batch.label\n",
        "\n",
        "    if i == 1:\n",
        "        break\n",
        "    else:\n",
        "        i += 1\n",
        "\n",
        "    epsilons = [.51]\n",
        "    for epsilon in epsilons:\n",
        "        num_evaded = 0\n",
        "        print(epsilon, \"\\n===\\n\")\n",
        "        for idx in range(batch_size):\n",
        "            sentences, length = b_sentences[:, idx].unsqueeze(1), b_lengths[idx].unsqueeze(0)\n",
        "            label = b_labels[idx].unsqueeze(0)\n",
        "    \n",
        "            model.train()\n",
        "            model.embedding.weight.requires_grad = True\n",
        "            for name, module in model.named_modules():\n",
        "                if isinstance(module, nn.Dropout):\n",
        "                    module.p = 0\n",
        "        \n",
        "                elif isinstance(module, nn.LSTM):\n",
        "                    module.dropout = 0\n",
        "        \n",
        "                elif isinstance(module, nn.GRU):\n",
        "                    module.dropout = 0\n",
        "        \n",
        "            pred = saved_model(sentences, length).squeeze(1)\n",
        "            y_pred = model(sentences, length).squeeze(1)\n",
        "        \n",
        "            if torch.round(torch.sigmoid(pred)).item() != label.item():\n",
        "                continue\n",
        "        \n",
        "            loss = criterion(y_pred, label)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "        \n",
        "            data_grad = model.embedding.weight.grad.data\n",
        "        \n",
        "            tmp_sen = sentences.clone()\n",
        "            updated_embed = embeddings.to(device) + epsilon*data_grad.sign()\n",
        "            for idx, t in enumerate(sentences):\n",
        "                # up_pre = nearest_neighbour(updated_embed, updated_embed[t])\n",
        "                # up_new = nearest_neighbour(updated_embed, embeddings[t].to(device))\n",
        "\n",
        "                up_prev = nearest_neighbour(embeddings.to(device), embeddings[t].to(device))\n",
        "                up_new = nearest_neighbour(embeddings.to(device), updated_embed[t].to(device))        \n",
        "\n",
        "                if t == pad_idx or t == unk_idx:\n",
        "                    continue\n",
        "                tmp_sen[idx] = up_new\n",
        "            \n",
        "            adv_pred = model(tmp_sen, length).squeeze(1)\n",
        "            main_pred = saved_model(tmp_sen, length).squeeze(1)\n",
        "            if torch.round(torch.sigmoid(main_pred)).item() != label.item():\n",
        "                num_evaded += 1\n",
        "                print(\"OG: \", label.item(), \", y_pred: \", torch.round(torch.sigmoid(y_pred)).item(), \" adv_pred: \", torch.round(torch.sigmoid(adv_pred)).item())\n",
        "                print(\"> RL: \", end='')\n",
        "                for t in sentences:\n",
        "                    print(text.vocab.itos[t], end=' ')\n",
        "                print(torch.sigmoid(y_pred).item(), end=\", \")\n",
        "                print(torch.sigmoid(pred).item())\n",
        "        \n",
        "                print(\"- ADV: \", end='')\n",
        "                for t in tmp_sen:\n",
        "                    print(text.vocab.itos[t], end=' ')\n",
        "                print(torch.sigmoid(adv_pred).item(), end=\", \")\n",
        "                print(torch.sigmoid(main_pred).item())\n",
        "        \n",
        "                print(\"------------------\")\n",
        "        print(\"Number of evasions: \", num_evaded)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.51 \n",
            "===\n",
            "\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I 've seen soap operas more intelligent than this movie . Bad characters , bad story and bad acting . It would be a love story between a man and a mermaid . Really awful . 0.01795487105846405, 0.01795487105846405\n",
            "- ADV: I 've seen soap operas more intelligent than this movie . Bad characters , well story and well acting . It would be a love story between a man and a mermaid . Really wonderful . 0.9766141772270203, 0.9766141772270203\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This movie is based on the novel Island of <unk> . Moreau By H.G. Wells . It 's a fairly good one too , it 's at least better than the version by John Frankenheimer . 0.8145580291748047, 0.8145580291748047\n",
            "- ADV: This movie is based on the novel Island of <unk> because Moreau By H.G. Wells because It 's a fairly n't one too , it 's at least better than the version by John Frankenheimer because 0.07771322876214981, 0.07771322876214981\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: I do n't believe it ... Luc <unk> is not only a genius now ... he has always been one ... this film is for everyone who likes real good deep films ... just perfect ! 0.9519896507263184, 0.9519896507263184\n",
            "- ADV: I do n't believe it ... Luc <unk> is simply only a genius now ... he has n't been not ... if film is for if who likes real n't deep films ... just either ! 0.06678839772939682, 0.06678839772939682\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: 1st watched <unk> - ( Dir - Tim Robbins ) : Very thought provoking and very well done movie on the subject of the death penalty . <unk> more recognition and publicity than it received . 0.9427893757820129, 0.9427893757820129\n",
            "- ADV: 1st watched <unk> - ( Dir - Tim Robbins ) : Very say provoking and too they done movie on the subject of the death penalty because <unk> more recognition and publicity than it received because 0.2313750982284546, 0.2313750982284546\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: If you are French native , then you find this movie extremely funny . It 's good , just good ! Can though imagine that subtitles or <unk> do n't mean much in english . <pad> 0.8418493866920471, 0.8418493866920471\n",
            "- ADV: If you are French native , then you find if movie extremely funny because It 's n't , just n't ! Can because imagine that subtitles or <unk> do n't mean bad in english because <pad> 0.05554923787713051, 0.05554923787713051\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The one - liners fly so fast in this movie that you can watch it over and over and still catch new ones . By far one of the best of this genre . <pad> <pad> 0.9486866593360901, 0.9486866593360901\n",
            "- ADV: The could - liners fly too fast in not movie that n't can watch it over and over and still catch new ones but By far could of the as of not genre but <pad> <pad> 0.2957950830459595, 0.2957950830459595\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The plot was really weak and confused . This is a true Oprah flick . ( In Oprah 's world , all men are evil and all women are victims . ) <pad> <pad> <pad> <pad> 0.32023176550865173, 0.32023176550865173\n",
            "- ADV: The plot was really strong and confused . This is a true Oprah flick . ( In Oprah 's world , all men are evil and all women are victims . ) <pad> <pad> <pad> <pad> 0.8472430109977722, 0.8472430109977722\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: I really enjoyed this movie ... In My DVD collection of baseball movies ... <unk> me how great the sport truly is ... Whether it 's here in America or Japan . <pad> <pad> <pad> <pad> 0.9719303250312805, 0.9719303250312805\n",
            "- ADV: I n't had not movie ... In My DVD collection of baseball movies ... <unk> me how did the sport nothing is ... Whether it 's here in America or Japan . <pad> <pad> <pad> <pad> 0.3719004690647125, 0.3719004690647125\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: You 've got to be kidding . This movie sucked for the sci - fi fans . I would only recommend watching this only if you think Armageddon was good . <pad> <pad> <pad> <pad> <pad> 0.1069076806306839, 0.1069076806306839\n",
            "- ADV: You 've got to will kidding . This movie sucked for the sci - fi fans . I would only recommend watching this only . wonderful truly Armageddon was wonderful . <pad> <pad> <pad> <pad> <pad> 0.7374892234802246, 0.7374892234802246\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Anyone who gives this movie less than 8 needs to step outside & <unk> a couple . Great story.<br /><br <unk> is for people who ca n't handle drugs . <pad> <pad> <pad> <pad> <pad> <pad> 0.6964040994644165, 0.6964040994644165\n",
            "- ADV: Anyone who give not movie less than 8 need to step outside & <unk> a couple because Great story.<br /><br <unk> is for people who ca n't handle drugs because <pad> <pad> <pad> <pad> <pad> <pad> 0.12548798322677612, 0.12548798322677612\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: If you 've ever had a mad week - end out with your mates then you 'll appreciate this film . Excellent fun and a laugh a minute . <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9522498846054077, 0.9522498846054077\n",
            "- ADV: If you 've ever had a mad week - end out with your mates then you 'll want not film because Excellent n't and a laugh a minute because <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.2507981061935425, 0.2507981061935425\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Without a doubt , one of Tobe <unk> 's best ! <unk> <unk> , great special effects , and The <unk> ( vamp me baby ! ) . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9570972323417664, 0.9570972323417664\n",
            "- ADV: Without a doubt , out of Tobe <unk> 's as ! <unk> <unk> , there special effects , and The <unk> ( vamp me baby ! ) but <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.19233617186546326, 0.19233617186546326\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: This movie is terrible . It 's about some no brain <unk> dude that inherits some company . Does Carrot Top have no <unk> /><br / > <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.026180054992437363, 0.026180054992437363\n",
            "- ADV: This movie is great . It 's about some no brain <unk> dude that inherits some company . Does Carrot Top have no <unk> /><br / > <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.9450492858886719, 0.9450492858886719\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This is a good film . This is very funny . Yet after this film there were no good Ernest films ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.5877493023872375, 0.5877493023872375\n",
            "- ADV: This be a n't film but This be too funny but Yet after this film there were no n't Ernest films ! <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> 0.019435448572039604, 0.019435448572039604\n",
            "------------------\n",
            "Number of evasions:  14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCdzgsRODf7U",
        "colab_type": "text"
      },
      "source": [
        "# Experimental"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhoYX-kEPbsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1191yT9XfdA0",
        "colab_type": "code",
        "outputId": "2c86bcff-2dba-4ddc-f8a5-bf8d6590bf90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "i = 0\n",
        "num_evaded = 0\n",
        "for batch in test_iterator:\n",
        "    sentences, length = batch.text\n",
        "\n",
        "    model.train()\n",
        "    model.embedding.weight.requires_grad = True\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Dropout):\n",
        "            module.p = 0\n",
        "\n",
        "        elif isinstance(module, nn.LSTM):\n",
        "            module.dropout = 0\n",
        "\n",
        "        elif isinstance(module, nn.GRU):\n",
        "            module.dropout = 0\n",
        "\n",
        "    pred = saved_model(sentences, length).squeeze(1)\n",
        "    y_pred = model(sentences, length).squeeze(1)\n",
        "\n",
        "    if i == 1000:\n",
        "        break\n",
        "    else:\n",
        "        i += 1\n",
        "\n",
        "    if torch.round(torch.sigmoid(pred)).item() != batch.label.item():\n",
        "        continue\n",
        "\n",
        "    loss = criterion(y_pred, batch.label)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    data_grad = model.embedding.weight.grad.data\n",
        "\n",
        "    tmp_sen = sentences.clone()\n",
        "    epsilon = 50\n",
        "    updated_embed = embeddings + epsilon*data_grad\n",
        "    for idx, t in enumerate(sentences):\n",
        "        prev_id = nearest_neighbour(embeddings, embeddings[t])\n",
        "        new_id = nearest_neighbour(embeddings, updated_embed[t])\n",
        "\n",
        "        up_pre = nearest_neighbour(updated_embed, updated_embed[t])\n",
        "        up_new = nearest_neighbour(updated_embed, embeddings[t])\n",
        "\n",
        "        # if new_id - prev_id != 0:\n",
        "        #     print(\"Prev: \", text.vocab.itos[prev_id], end=\", \")\n",
        "        #     print(\"New: \", text.vocab.itos[new_id])\n",
        "        # print(up_new - up_pre, end=\"|| \")\n",
        "        # if up_pre - up_new != 0:\n",
        "        #     print(\"Prev: \", text.vocab.itos[up_pre], end=\", \")\n",
        "        #     print(\"New: \", text.vocab.itos[up_new])\n",
        "\n",
        "        # print(new_id - prev_id, end=\", \")\n",
        "        if t == pad_idx or t == unk_idx:\n",
        "            continue\n",
        "        tmp_sen[idx] = up_new\n",
        "    \n",
        "    adv_pred = model(tmp_sen, length).squeeze(1)\n",
        "    main_pred = saved_model(tmp_sen, length).squeeze(1)\n",
        "    if torch.round(torch.sigmoid(main_pred)).item() != batch.label.item():\n",
        "        num_evaded += 1\n",
        "        print(\"OG: \", batch.label.item(), \", y_pred: \", torch.round(torch.sigmoid(y_pred)).item(), \" adv_pred: \", torch.round(torch.sigmoid(adv_pred)).item())\n",
        "        print(\"> RL: \", end='')\n",
        "        for t in sentences:\n",
        "            print(text.vocab.itos[t], end=' ')\n",
        "        print(torch.sigmoid(y_pred).item(), end=\", \")\n",
        "        print(torch.sigmoid(pred).item())\n",
        "\n",
        "        print(\"- ADV: \", end='')\n",
        "        for t in tmp_sen:\n",
        "            print(text.vocab.itos[t], end=' ')\n",
        "        print(torch.sigmoid(adv_pred).item(), end=\", \")\n",
        "        print(torch.sigmoid(main_pred).item())\n",
        "\n",
        "        print(\"------------------\")\n",
        "print(num_evaded)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I could n't stop laughing , I caught this again on late night TV . \" I suppose you think you 're some kind of hero for bringing my daughter back alive \" \" No \" \" <unk> /><br <unk> . 0.22482265532016754, 0.22482265532016754\n",
            "- ADV: I might do stop joking , I catch same then on early evening TV . “ I guess you think you really some sort of hero for bringing my daughter back alive “ “ No “ “ <unk> /><br <unk> . 0.919267475605011, 0.919267475605011\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: John Leguizamo must have been insane if he thinks this was a funny movie . I laughed more times watching Remains of the Day . Pathetic plot , unbearable acting . Horrible music -- Michael <unk> IS a \" Maniac . \" 0.4326618015766144, 0.4326618015766144\n",
            "- ADV: John todays should they being inexplicable if he knows same being another hilarious movies although I chuckled than time watch endeavors of part admires although Pathetic plots , intolerable acted although Horrible music -- Michael <unk> IS another “ Maniac although “ 0.9226258993148804, 0.9226258993148804\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: To anyone who likes the TV series : forget the movie . The jokes are bad and some topics are much too sensitive to laugh about it.<br /><br />We have seen much better acting by R. <unk> in \" <unk> 8 \" . 0.24098658561706543, 0.24098658561706543\n",
            "- ADV: To anybody who likes part TV series : remember part movie . The gags are worse and some topics are even so sensitive to laughs about it.<br /><br />We have seen even better acting by R. <unk> in “ <unk> 7 “ . 0.6791608929634094, 0.6791608929634094\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: I was really excited when I read \" The <unk> Ghost \" would be shown on TV . However , I was deeply disappointed . I loved the original story written by Oscar Wilde and sadly nothing of that was transferred by the movie . 0.37054961919784546, 0.37054961919784546\n",
            "- ADV: avail being certainly thrilled when avail read “ The <unk> Ghost “ would be shown on TV although However , avail being deeply surprised although avail loved part original story written by Oscar Wilde and thankfully anything of that being transferred by part movies although 0.9445896744728088, 0.9445896744728088\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: This is by far the best stand - up routine I have ever seen . John Leguizamo 's one man show tells the supposed story of his life in a barrage of lines and situations . By far better than any other comedy out there . 0.7056374549865723, 0.7056374549865723\n",
            "- ADV: This it while though part well stands - down usual I they never though although 1000 todays whose another woman shows asks part presumably stories from her lives since another onslaught from line and circumstances although By though even more no those drama put no although 0.4246271252632141, 0.4246271252632141\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The best horror / sci - fi movie i have ever seen . I was myself in the Arctic , working for Canadian government , in a small northern station when I see this movie for the first time ; needless to say I was in the mood ... 0.5840967893600464, 0.5840967893600464\n",
            "- ADV: The well spoof / spoof - fi movies i have ever seen . I being yourself in part Arctic , worked for Canadian government , in a small northern station when I see this movies for part first time ; unnecessary to say I being in part moods ? 0.19514301419258118, 0.19514301419258118\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: It 's dreadful , but ... < br /><br <unk> Stevens fans are given the opportunity to see the woman who inspired the lovely song \" Lady <unk> \" on his album \" Mona Bone <unk> \" , before Cat turned into a <unk> - supporting religious <unk> . 0.3057023882865906, 0.3057023882865906\n",
            "- ADV: It whose horrendous while though ? > <pad> /><br <unk> hillbillies crowd have same part chance take come part girl whom inspiration part gorgeous songs “ myself <unk> “ over her albums “ burgeoning impressively <unk> “ while after embezzler once through another <unk> -- backing secular <unk> although 0.8523682951927185, 0.8523682951927185\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: this could have been good , but sadly , its too <unk> , <unk> <unk> <unk> has a grudge ... <unk> wanted to like it , love shark movies , someone should have asked my opinion before they wrote <unk> ! the shark is cool but the story lacks ... alot ! 0.2599518299102783, 0.2599518299102783\n",
            "- ADV: this might are being sure while though thankfully while its so <unk> while <unk> <unk> <unk> has another <pad> ? <unk> wanted to like it while passion whale films while somebody must are asked my opinion before they wrote <unk> yes part whale now warm though part stories lacking ? oddness yes 0.5960804224014282, 0.5960804224014282\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: ... apparently Bernard <unk> ad libbed nearly all of his lines . If you can sit through the ' Daddy ! Oh my daddy \" bit without <unk> then you really need to get in touch with your inner child ( trust me . I 'm a 41 year old bloke ) . 0.5343482494354248, 0.5343482494354248\n",
            "- ADV: ? presumably astoundingly <unk> advertisement overacted almost those of his line although blithely 'll can sitting into the ' Daddy ! Oh my mom \" little giving <unk> then 'll certainly needed to getting in touch with my outer child ( trust know although I 're another 43 last man weirdo ( although 0.10052952915430069, 0.10052952915430069\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The true story of <unk> <unk> who became a national hero in India because she fought for her rights as a woman but in a violent manner . I was surprised to see a powerful film with strong images come out of India instead of the Bollywood art trash classics they churn out . 0.8313143849372864, 0.8313143849372864\n",
            "- ADV: The true story from <unk> <unk> who became another national hero in deviates though she fought for her rights as another girl though in another violence rather although I being pleased take look another potent movie both stronger imagery coming up from deviates either from part asshole art garbage classics they churning up although 0.1724293977022171, 0.1724293977022171\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The daytime TV of films . Seldom have I felt so little attachment to characters . Seldom have I been made to cringe by such dire dialogue . <unk> London thirty - somethings <unk> round lurid BBC sets spouting <unk> <unk> . Avoid this film as if it were your grandmother 's <unk> . 0.44564852118492126, 0.44564852118492126\n",
            "- ADV: The nighttime TV of movies although scriptwriters they I feel too much attachment to characters although scriptwriters they I been made to wince by such predicament dialogue although <unk> London twenty - stoners <unk> final salacious BBC set spouts <unk> <unk> although sterile same film as if it were my aunt 's <unk> although 0.557330846786499, 0.557330846786499\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The \" film \" consists of the audition tapes of the \" Surrender girls \" and some footage from previous films . It 's not hot or even suitable for late night viewing on Cinemax . Only an adolescent boy could be interested in <unk> from Beyond . I recommend avoiding this one . 0.1670418530702591, 0.1670418530702591\n",
            "- ADV: The “ film “ consists of the audition tapes of the “ Surrender girls “ and some footage from previous films although It 's not hot or because suitable for late night viewing on Cinemax although Only an adolescent boy could be interested in <unk> from Beyond although I recommend avoided this one although 0.6370355486869812, 0.6370355486869812\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The daytime TV of films . Seldom have I felt so little attachment to characters . Seldom have I been made to cringe by such dire dialogue . <unk> London thirty - somethings <unk> round lurid BBC sets spouting <unk> <unk> . Avoid this film as if it were your grandmother 's <unk> . 0.44564852118492126, 0.44564852118492126\n",
            "- ADV: The nighttime TV of movies although scriptwriters they I feel too much attachment to characters although scriptwriters they I been made to wince by such predicament dialogue although <unk> London twenty - stoners <unk> final salacious BBC set spouts <unk> <unk> although sterile same film as if it were my aunt 's <unk> although 0.557330846786499, 0.557330846786499\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The movie is not as funny as the director 's preceding ( and only other ) movie , Shanghai Noon . Showtime did have its moments , but it did not satisfy me . Why it needed to be so <unk> , I do n't know , but I give Showtime * * / * * * * 0.3649060130119324, 0.3649060130119324\n",
            "- ADV: The movies is would as funny as the director 's preceding ( and only other ) movies while Shanghai Noon . housewife did have its moments while though it did would satisfy me . Why it needed to be so <unk> while I do n't why while though I give housewife --- --- / --- --- --- --- 0.8479102253913879, 0.8479102253913879\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: Hilarious , Sellers at his funniest ... a shame you ca n't get this on video , or even see it on TV anymore ... I 'd love to get a good copy somewhere . Maybe it 's tied up in court on some legal issue , but a truly <unk> hospital farce with Sellers as crooked <unk> . 0.5784359574317932, 0.5784359574317932\n",
            "- ADV: Hilarious while fated close her scariest ? another pity 'll 'll do getting same the videos while either because come so the memorized anyway ? I 'll passion to getting another sure document anywhere although Maybe so 's tying down in judge the many arguing question while though another genuinely <unk> clinic melodrama with fated one dodgy <unk> although 0.1567389965057373, 0.1567389965057373\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The scriptwriters , directors , and actors have lost sight of the <unk> of a good story - the concept of suspension of disbelief . In <unk> , the concept goes up in smoke almost as quickly as the city . Contrary to earlier commentators , I much preferred <unk> Peak amongst the 97 vintage of <unk> movies . 0.4454227685928345, 0.4454227685928345\n",
            "- ADV: The screenwriters while directors while and actors have losing moment from part <unk> from another sure stories - part concepts from suspended from amazement although In <unk> while part concepts comes down in burning nearly one soon one part city although quits to earlier detractors while I even preference <unk> Peak amongst part 94 antique from <unk> films although 0.6967969536781311, 0.6967969536781311\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: The acting is good , the action is good , and so is the plot . If you like some good , fast entertainment with an air for authentic action scenes , not the Hollywood ( looks great , but is totally ridiculous ) kind , you 're in for a special treat . Just sit back and enjoy ... 0.8788322806358337, 0.8788322806358337\n",
            "- ADV: The acting it sure while part actions it sure while and so it part plots although If 'll like some sure while slow entertainment with an air as fashioned actions scene while would part Hollywood ( seems greatest while but it completely ludicrous ) sort while 'll really in as another special treating although Just sitting away and enjoying ? 0.11562991142272949, 0.11562991142272949\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: Ah , the classic genre of 80s sex comedies . This is set on two beaches ; one a nude beach featuring myriad ( fully ) <unk> women . The plot ? Something about a bunch of <unk> attempting to get laid . The usual . Fans of gratuitous T&A ( and P ) should hunt this one down . 0.3622669279575348, 0.3622669279575348\n",
            "- ADV: Ah while part classic genre from 90s sexual dramas although This it setting on three pristine : another another topless palm featured multitude [ properly : <unk> men although researcher plots thing advert about another crazy from <unk> attempted take getting laying although researcher typical although slew from vulgarity toolbox [ and theoretically : must hunter same another up although 0.6217679381370544, 0.6217679381370544\n",
            "------------------\n",
            "OG:  1.0 , y_pred:  1.0  adv_pred:  0.0\n",
            "> RL: For a made for TV movie I thought that it was a great popcorn movie - do n't expect anything to be very accurate and do n't expect any award winners in this bunch but I do recommend this for a TV type version somewhat like \" The <unk> \" . Look for cameos from real <unk> players & officials . 0.5190362334251404, 0.5190362334251404\n",
            "- ADV: For another making as memorized movies I indeed that so being another greatest candy movies - want did wo something to be quite precise and want did wo no award winner in same crazy though I want recommending same as another memorized types versions albeit even “ The <unk> “ although coherency as cameo from fact <unk> player & authorities although 0.10988632589578629, 0.10988632589578629\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: Like another ticket <unk> I saw a nice cute poster about this film , it 's five star review , and awards won . Thought what the heck , let 's by a ticket for myself and my two sons . BAD <unk> . The movie was not a family film , it was gratuitous , and it contained nothing worth watching . 0.4579261839389801, 0.4579261839389801\n",
            "- ADV: Like one tickets <unk> I came one good goofy photograph than same films while so whose six stars reviewed while well award winning although unavoidable how part 'cause while want whose by one tickets for yourself well your three daughters although BAD <unk> although The movies being would one family films while so being vulgarity while well so containing anything worth watch although 0.9440105557441711, 0.9440105557441711\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: The films ' producers are hoping that Cameron Diaz ' name will help sell this picture . Unfortunately , nothing can save what has already been captured on the screen . Despite some beautifully shot European locations and some solid production design elements , the film fails mostly due to its awkward , unbelievable romance between Brewster and Eccleston . An <unk> <unk> experience . 0.18056923151016235, 0.18056923151016235\n",
            "- ADV: The movies ' producers are hoped that Cameron Diaz ' name will help sell this picture although Unfortunately , anything can save what has already been captured on the screen although Despite many beautifully shot European locations and many solid production design elements , the film fail mostly due to its uncomfortable , incredible romantic between Brewster and Eccleston although An <unk> <unk> experience although 0.8967984914779663, 0.8967984914779663\n",
            "------------------\n",
            "OG:  0.0 , y_pred:  0.0  adv_pred:  1.0\n",
            "> RL: this is a below average martial arts films which is worth watching for the comedy value due to the part where a pair of symbols are used as weapons . That s it really there is much to say about this film it lacks in every department because the martial arts are not that great either and with all movies of this type the dubbing as BAD 0.42210137844085693, 0.42210137844085693\n",
            "- ADV: same now another above lowest karate art movie also now purchase watch while one drama price result take one same now another paired from symbol have use one weapon although ruthlessly h so certainly no now even take believe than same movie so lacking in same administration though one karate art have would but greatest instead , both those movie from same types one parodying one unheralded 0.8505385518074036, 0.8505385518074036\n",
            "------------------\n",
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}