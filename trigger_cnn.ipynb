{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trigger_cnn",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e368a95c72aa4a82b66d8a491860965d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5b72a43ec5f43558690e545e80f6f5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f7d07b6a80d4e0ea9ca92ac65eedc4c",
              "IPY_MODEL_5d15e35261204cc994da6708935d39de"
            ]
          }
        },
        "e5b72a43ec5f43558690e545e80f6f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f7d07b6a80d4e0ea9ca92ac65eedc4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39ffa82aba2742ef89f25353bb7646bd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 392,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 392,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5991501e4f64e59baef592497ae7e93"
          }
        },
        "5d15e35261204cc994da6708935d39de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c14d95ef185842a5a56fc180030e954b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 392/392 [15:43&lt;00:00,  1.47it/s, e: 0/3 =&gt; (T/V) Loss: 0.506 | 0.335, Acc: 73.912 | 85.699\n]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e1dc87bfff22487cae48b94125b536e0"
          }
        },
        "39ffa82aba2742ef89f25353bb7646bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5991501e4f64e59baef592497ae7e93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c14d95ef185842a5a56fc180030e954b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e1dc87bfff22487cae48b94125b536e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23e75d7ae2ed4b1fa81123f5c4bb98a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fd8e502acf1343749e3f1bdf7c6c98c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b882bd837584e14958d212c75868a51",
              "IPY_MODEL_156c9a7dbb904e9b84c1d1763248b573"
            ]
          }
        },
        "fd8e502acf1343749e3f1bdf7c6c98c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b882bd837584e14958d212c75868a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_93e606ad8e5c402a9242895f4215b989",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 392,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 392,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4397fbcca51d4dd48b2f35d3b7ad940b"
          }
        },
        "156c9a7dbb904e9b84c1d1763248b573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c7a33251ada40268211a045f152d522",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 392/392 [15:36&lt;00:00,  1.47it/s, e: 1/3 =&gt; (T/V) Loss: 0.306 | 0.293, Acc: 86.994 | 87.910\n]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7904c38b8e7945bbb2354df3fc9d348a"
          }
        },
        "93e606ad8e5c402a9242895f4215b989": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4397fbcca51d4dd48b2f35d3b7ad940b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c7a33251ada40268211a045f152d522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7904c38b8e7945bbb2354df3fc9d348a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17ce8724a1be44a1a27697f4509efa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3af6bfe1bbc044debc39a73df77f2832",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_11e75e8b68ae4931accb9af471406035",
              "IPY_MODEL_3c5b5fc75c6149a29d74a3013211eecc"
            ]
          }
        },
        "3af6bfe1bbc044debc39a73df77f2832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11e75e8b68ae4931accb9af471406035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ce3164f43da44b2b97ce50e99145197d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 392,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 392,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfefe12998eb417192b362e7c8e0d22b"
          }
        },
        "3c5b5fc75c6149a29d74a3013211eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58528020d61e489aa2be70f9cb3877b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 392/392 [15:36&lt;00:00,  1.47it/s, e: 2/3 =&gt; (T/V) Loss: 0.225 | 0.287, Acc: 91.203 | 88.281\n]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bea4eac0451470297fbefc6f83bb2a5"
          }
        },
        "ce3164f43da44b2b97ce50e99145197d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfefe12998eb417192b362e7c8e0d22b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58528020d61e489aa2be70f9cb3877b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bea4eac0451470297fbefc6f83bb2a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "45KE_J3dMktm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "utils.py\n",
        "'''\n",
        "import heapq\n",
        "from copy import deepcopy\n",
        "import numpy\n",
        "from operator import itemgetter\n",
        "\n",
        "import torch\n",
        "from torch.utils.model_zoo import tqdm\n",
        "\n",
        "def hotflip_attack(averaged_grad, embedding_matrix, trigger_token_ids,\n",
        "                   increase_loss=False, num_candidates=1):\n",
        "    \"\"\"\n",
        "    Borrowed from @Eric-Wallace\n",
        "\n",
        "    This function takes in the model's average_grad over a batch of examples, the model's\n",
        "    token embedding matrix, and the current trigger token IDs. It returns the top token\n",
        "    candidates for each position.\n",
        "\n",
        "    If increase_loss=True, then the attack reverses the sign of the gradient and tries to increase\n",
        "    the loss (decrease the model's probability of the true class). For targeted attacks, you want\n",
        "    to decrease the loss of the target class (increase_loss=False).\n",
        "    \"\"\"\n",
        "    averaged_grad = averaged_grad.cpu()\n",
        "    embedding_matrix = embedding_matrix.cpu()\n",
        "    trigger_token_embeds = torch.nn.functional.embedding(torch.LongTensor(trigger_token_ids),\n",
        "                                                         embedding_matrix).detach().unsqueeze(0)\n",
        "    averaged_grad = averaged_grad.unsqueeze(0)\n",
        "\n",
        "    gradient_dot_embedding_matrix = torch.einsum(\"bij,kj->bik\",\n",
        "                                                 (averaged_grad, embedding_matrix))        \n",
        "    if not increase_loss:\n",
        "        gradient_dot_embedding_matrix *= -1    # lower versus increase the class probability.\n",
        "    if num_candidates > 1: # get top k options\n",
        "        _, best_k_ids = torch.topk(gradient_dot_embedding_matrix, num_candidates, dim=2)\n",
        "        return best_k_ids.detach().cpu().numpy()[0]\n",
        "    _, best_at_each_step = gradient_dot_embedding_matrix.max(2)\n",
        "    return best_at_each_step[0].detach().cpu().numpy()\n",
        "\n",
        "def get_best_candidates(model, batch, criterion,trigger_token_ids, cand_trigger_token_ids, device, beam_size=1):\n",
        "    \"\"\"\"\n",
        "    Borrowed from @Eric-Wallace\n",
        "\n",
        "    Given the list of candidate trigger token ids (of number of trigger words by number of candidates\n",
        "    per word), it finds the best new candidate trigger.\n",
        "    This performs beam search in a left to right fashion.\n",
        "    \"\"\"\n",
        "    # first round, no beams, just get the loss for each of the candidates in index 0.\n",
        "    # (indices 1-end are just the old trigger)\n",
        "    loss_per_candidate = get_loss_per_candidate(0, model, batch, criterion,trigger_token_ids,\n",
        "                                                cand_trigger_token_ids, device)\n",
        "    # maximize the loss\n",
        "    top_candidates = heapq.nlargest(beam_size, loss_per_candidate, key=itemgetter(1))\n",
        "\n",
        "    # top_candidates now contains beam_size trigger sequences, each with a different 0th token\n",
        "    for idx in range(1, len(trigger_token_ids)): # for all trigger tokens, skipping the 0th (we did it above)\n",
        "        loss_per_candidate = []\n",
        "        for cand, _ in top_candidates: # for all the beams, try all the candidates at idx\n",
        "            loss_per_candidate.extend(get_loss_per_candidate(idx, model, batch, criterion,cand,\n",
        "                                                             cand_trigger_token_ids, device))\n",
        "        top_candidates = heapq.nlargest(beam_size, loss_per_candidate, key=itemgetter(1))\n",
        "    return max(top_candidates, key=itemgetter(1))[0]\n",
        "\n",
        "def get_loss_per_candidate(index, model, batch, criterion, trigger_token_ids, cand_trigger_token_ids, device):\n",
        "    \"\"\"\n",
        "    Borrowed from @Eric-Wallace\n",
        "\n",
        "    For a particular index, the function tries all of the candidate tokens for that index.\n",
        "    The function returns a list containing the candidate triggers it tried, along with their loss.\n",
        "    \"\"\"\n",
        "    if isinstance(cand_trigger_token_ids[0], (numpy.int64, int)):\n",
        "        print(\"Only 1 candidate for index detected, not searching\")\n",
        "        return trigger_token_ids\n",
        "\n",
        "    loss_per_candidate = []\n",
        "    # loss for the trigger without trying the candidates\n",
        "    curr_loss = evaluate_batch_trigger(model, batch, criterion, trigger_token_ids, device)['loss'] \\\n",
        "                    .cpu().detach().numpy()\n",
        "\n",
        "    loss_per_candidate.append((deepcopy(trigger_token_ids), curr_loss))\n",
        "    for cand_id in range(len(cand_trigger_token_ids[0])):\n",
        "        trigger_token_ids_one_replaced = deepcopy(trigger_token_ids) # copy trigger\n",
        "        trigger_token_ids_one_replaced[index] = cand_trigger_token_ids[index][cand_id] # replace one token\n",
        "\n",
        "        loss = evaluate_batch_trigger(model, batch, criterion, trigger_token_ids_one_replaced, device)['loss'].cpu().detach().numpy()\n",
        "        \n",
        "        ''' Keep senti words loss 0'''\n",
        "        # if cand_id in senti_word_id:\n",
        "        #     loss = 0\n",
        "        loss_per_candidate.append((deepcopy(trigger_token_ids_one_replaced), loss))\n",
        "\n",
        "    return loss_per_candidate\n",
        "\n",
        "################################\n",
        "\n",
        "def accuracy(y_pred, y_orig):\n",
        "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "    correct = (y_pred == y_orig).float()\n",
        "    accuracy = correct.sum() / len(correct)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def get_accuracy(model, iterator, criterion,trigger_token_ids, device):\n",
        "    epoch_acc = 0\n",
        "\n",
        "    print(\"Finding accuracy...\")\n",
        "    pbar = tqdm(enumerate(iterator), total=len(iterator))\n",
        "    for _, batch in pbar:\n",
        "        model.eval()\n",
        "        res = evaluate_batch_trigger(model, batch, criterion, trigger_token_ids, device)\n",
        "\n",
        "        epoch_acc += res['acc']\n",
        "    return epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate_batch_trigger(model, batch, criterion,trigger_token_ids, device):\n",
        "    # model.eval()\n",
        "    text = batch.text\n",
        "    num_trigger_tokens = len(trigger_token_ids)\n",
        "\n",
        "    # Append trigger tokens\n",
        "    with torch.no_grad():\n",
        "        trigger_sequence_tensor = torch.LongTensor(deepcopy(trigger_token_ids)) # or 2\n",
        "        trigger_sequence_tensor = trigger_sequence_tensor.repeat(batch.label.shape[0], 1) # batch_size is global\n",
        "        b_text = torch.cat((trigger_sequence_tensor, text.cpu()), dim=1)\n",
        "    \n",
        "        y_pred = model(b_text.cuda()).squeeze(1)\n",
        "        loss = criterion(y_pred, batch.label.to(device))\n",
        "        acc = accuracy(y_pred, batch.label.cuda())\n",
        "\n",
        "    return {'acc': acc, 'loss': loss}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB_zY45S2pFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# network.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Classify_cnn(nn.Module):\n",
        "    def __init__(self,\n",
        "                vocab_size, embedding_dim, output_dim,\n",
        "                num_filters, filter_sizes,\n",
        "                dropout, pad_idx):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "\n",
        "        self.convLayers = nn.ModuleList([\n",
        "                            nn.Conv2d(1, num_filters, kernel_size = (filter_size, embedding_dim))\n",
        "                            for filter_size in filter_sizes\n",
        "        ])\n",
        "\n",
        "        self.linear = nn.Linear(len(filter_sizes) * num_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        '''\n",
        "        Args:\n",
        "            text: Size - (batch_size, len(text))\n",
        "        '''\n",
        "        embedded = self.embedding(text)   # Size - (batch_size, len(text), embed_dim)\n",
        "        embedded = embedded.unsqueeze(1)     # Size - (batch_size, 1, len(text), embed_dim)\n",
        "\n",
        "        convolve = [    \n",
        "            F.relu(conv(embedded)).squeeze(3)    # Size - (batch_size, num_filters, len(text) - filter_size + 1)\n",
        "            for conv in self.convLayers    \n",
        "        ]\n",
        "        \n",
        "        pool = [\n",
        "            F.max_pool1d(conv, conv.shape[2]).squeeze(2) # Size - (batch_size, num_filters)\n",
        "            for conv in convolve\n",
        "        ]\n",
        "\n",
        "        cat = self.dropout(torch.cat(pool, dim=1))  # Size - (batch_size, num_filter * len(filter_sizes)\n",
        "        return self.linear(cat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZomslDUDDZgC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext as tt\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.model_zoo import tqdm\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "\n",
        "# from utils import *\n",
        "# from network import RNN\n",
        "\n",
        "SEED = 1\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\n",
        "            'cuda' if torch.cuda.is_available()\n",
        "            else 'cpu')\n",
        "\n",
        "\n",
        "def train_batch(model, batch, optimizer, criterion):\n",
        "    optimizer.zero_grad()\n",
        "    text = batch.text\n",
        "    \n",
        "    y_pred = model(text).squeeze(1)\n",
        "    loss = criterion(y_pred, batch.label)\n",
        "    acc = accuracy(y_pred, batch.label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), acc.item()\n",
        "\n",
        "def evaluate_batch(model, batch, criterion):\n",
        "    with torch.no_grad():\n",
        "        text = batch.text\n",
        "    \n",
        "        y_pred = model(text).squeeze(1)\n",
        "        loss = criterion(y_pred, batch.label)\n",
        "        acc = accuracy(y_pred, batch.label)\n",
        "\n",
        "    return loss.item(), acc.item()\n",
        "\n",
        "def time_min_sec(s, e):\n",
        "    diff = e - s\n",
        "    diff_min = int(diff / 60)\n",
        "    diff_sec = int(diff - (diff_min * 60))\n",
        "\n",
        "    return diff_min, diff_sec\n",
        "\n",
        "extracted_grads = []\n",
        "def extract_grad_hook(module, grad_in, grad_out):\n",
        "    extracted_grads.append(grad_out[0])\n",
        "\n",
        "'''\n",
        "Main function\n",
        "'''\n",
        "\n",
        "import re\n",
        "import spacy\n",
        "def tokenizer(sentence):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sentence)\n",
        "\n",
        "    # Remove numbers\n",
        "    sentence = re.sub('[0-9]+', ' ', sentence)\n",
        "\n",
        "    # # Single character removal\n",
        "    # sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return [x.text for x in NLP.tokenizer(sentence) if x.text != \" \"]\n",
        "\n",
        "def preprocessor(tokenized_text):\n",
        "    tmp = []\n",
        "    for text in tokenized_text:\n",
        "        if text == \"n't\":\n",
        "            tmp.append(\"not\")\n",
        "        elif re.match(r'<[^>]+>', text) is not None:\n",
        "            tmp.append(text)\n",
        "    \n",
        "    return tokenized_text\n",
        "\n",
        "NLP = spacy.load('en_core_web_sm')\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n",
        "c_text = tt.data.Field(tokenize=tokenizer, batch_first=True,\n",
        "                       lower=True) \n",
        "c_label = tt.data.LabelField(dtype=torch.float)\n",
        "\n",
        "train_data, test_data = tt.datasets.IMDB.splits(c_text, c_label)\n",
        "train_data, val_data = train_data.split(random_state=random.seed(SEED))\n",
        "\n",
        "VOCAB_SIZE = 16000\n",
        "\n",
        "# Vocab is lookup table for every word\n",
        "c_text.build_vocab(train_data,\n",
        "                max_size = VOCAB_SIZE,\n",
        "                vectors = 'glove.6B.100d',\n",
        "                unk_init = torch.Tensor.normal_)\n",
        "c_label.build_vocab(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VJpA9nSSOjs",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5LkQ83ASLdH",
        "colab_type": "code",
        "outputId": "16fa3499-0273-4515-8e80-197dcbd21167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300,
          "referenced_widgets": [
            "e368a95c72aa4a82b66d8a491860965d",
            "e5b72a43ec5f43558690e545e80f6f5e",
            "6f7d07b6a80d4e0ea9ca92ac65eedc4c",
            "5d15e35261204cc994da6708935d39de",
            "39ffa82aba2742ef89f25353bb7646bd",
            "d5991501e4f64e59baef592497ae7e93",
            "c14d95ef185842a5a56fc180030e954b",
            "e1dc87bfff22487cae48b94125b536e0",
            "23e75d7ae2ed4b1fa81123f5c4bb98a4",
            "fd8e502acf1343749e3f1bdf7c6c98c7",
            "9b882bd837584e14958d212c75868a51",
            "156c9a7dbb904e9b84c1d1763248b573",
            "93e606ad8e5c402a9242895f4215b989",
            "4397fbcca51d4dd48b2f35d3b7ad940b",
            "7c7a33251ada40268211a045f152d522",
            "7904c38b8e7945bbb2354df3fc9d348a",
            "17ce8724a1be44a1a27697f4509efa6e",
            "3af6bfe1bbc044debc39a73df77f2832",
            "11e75e8b68ae4931accb9af471406035",
            "3c5b5fc75c6149a29d74a3013211eecc",
            "ce3164f43da44b2b97ce50e99145197d",
            "dfefe12998eb417192b362e7c8e0d22b",
            "58528020d61e489aa2be70f9cb3877b6",
            "8bea4eac0451470297fbefc6f83bb2a5"
          ]
        }
      },
      "source": [
        "batch_size = 64\n",
        "train_iterator, \\\n",
        "val_iterator, \\\n",
        "test_iterator = tt.data.BucketIterator.splits(\n",
        "                    (train_data, val_data, test_data),\n",
        "                    batch_size = batch_size,\n",
        "                    device = device)\n",
        "\n",
        "# Initialize model\n",
        "input_dim = len(c_text.vocab)\n",
        "embedding_dim = 100 # Should be same as dim of pre trained embeddings\n",
        "output_dim = 1\n",
        "num_filters = 100\n",
        "filter_sizes = [3, 4, 5]\n",
        "dropout_rate = 0.5\n",
        "pad_idx = c_text.vocab.stoi[c_text.pad_token]\n",
        "\n",
        "model = Classify_cnn(input_dim, embedding_dim, output_dim,\n",
        "                     num_filters, filter_sizes, dropout_rate, pad_idx)\n",
        "\n",
        "# initialize embeddings\n",
        "pretrained_embeddings = c_text.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "unk_idx = c_text.vocab.stoi[c_text.unk_token]\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)\n",
        "\n",
        "print(\"Number of trainable parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model.to(device)\n",
        "criterion.to(device)\n",
        "\n",
        "# Train/Validate loop\n",
        "EPOCHS = 3\n",
        "history = {'loss': [], 'val_loss': [], 'acc': [], 'val_acc': []}\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train\n",
        "    loss, acc = 0, 0\n",
        "    model.train()\n",
        "    pbar = tqdm(total=len(train_iterator) + len(val_iterator))\n",
        "    for batch in train_iterator:\n",
        "        batch_loss, batch_acc= train_batch(model, batch, optimizer, criterion)\n",
        "        loss += batch_loss\n",
        "        acc += batch_acc\n",
        "        pbar.update(1)\n",
        "    \n",
        "    # Validate\n",
        "    model.eval()\n",
        "    val_loss, val_acc = 0, 0\n",
        "    for batch in val_iterator:\n",
        "        batch_loss, batch_acc= evaluate_batch(model, batch, criterion)\n",
        "        val_loss += batch_loss\n",
        "        val_acc += batch_acc\n",
        "        pbar.update(1)\n",
        "\n",
        "    loss, acc = loss/len(train_iterator), acc/len(train_iterator)\n",
        "    val_loss, val_acc = val_loss/len(val_iterator), val_acc/len(val_iterator)\n",
        "\n",
        "    history['loss'].append(loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['acc'].append(acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    pbar.set_postfix_str(\"e: {}/{} => (T/V) Loss: {:.3f} | {:.3f}, Acc: {:.3f} | {:.3f}\\n\". format(\n",
        "        epoch, EPOCHS, loss, val_loss, acc*100, val_acc*100))\n",
        "\n",
        "# torch.save(model, 'model.pb')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of trainable parameters:  1720801\n",
            "Classify_cnn(\n",
            "  (embedding): Embedding(16002, 100, padding_idx=1)\n",
            "  (convLayers): ModuleList(\n",
            "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
            "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
            "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
            "  )\n",
            "  (linear): Linear(in_features=300, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e368a95c72aa4a82b66d8a491860965d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=392.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e75d7ae2ed4b1fa81123f5c4bb98a4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=392.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17ce8724a1be44a1a27697f4509efa6e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=392.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQKACgYb2OGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "(fig, axes) = plt.subplots(nrows=1, ncols=2, figsize=(20,10))\n",
        "axes[0].plot(history['loss'], label=\"Train Loss\")\n",
        "axes[0].plot(history['val_loss'], label=\"Validate Loss\")\n",
        "axes[0].set_xlabel('epochs')\n",
        "axes[0].set_ylabel('loss')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        "axes[0].set_title('Loss curve')\n",
        "axes[0].grid('on')\n",
        "\n",
        "axes[1].plot(history['acc'], label=\"Train Accuracy\")\n",
        "axes[1].plot(history['val_acc'], label=\"Validate Accuracy\")\n",
        "axes[1].set_xlabel('epochs')\n",
        "axes[0].set_ylabel('accuracy')\n",
        "axes[1].legend(loc=\"lower right\")\n",
        "axes[1].set_title('Accuracy curve')\n",
        "axes[1].grid('on')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45vh9e7ZGIXa",
        "colab_type": "code",
        "outputId": "93757192-6955-4622-b1c8-757b61c7c0fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# Test loop\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = []\n",
        "orig = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "        text = batch.text\n",
        "        y_pred = model(text).squeeze(1)\n",
        "        y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "        pred.append(y_pred.cpu())\n",
        "        orig.append(batch.label.cpu())\n",
        "        \n",
        "    pred = torch.cat(pred, dim=0)\n",
        "    orig = torch.cat(orig, dim=0)\n",
        "def plot_confusion_matrix(pred_labels, labels):\n",
        "    \n",
        "    fig = plt.figure(figsize = (5,5));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, range(2));\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "plot_confusion_matrix(pred, orig)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfFwev79OdOZ",
        "colab_type": "text"
      },
      "source": [
        "# Triggers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6uCPuaZNpIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train 2\n",
        "\n",
        "'''\n",
        "Triggers\n",
        "'''\n",
        "# Attach hooks for gradients\n",
        "global extracted_grads\n",
        "extracted_grads = []\n",
        "for module in model.modules():\n",
        "    if isinstance(module, nn.Embedding):\n",
        "        module.register_backward_hook(extract_grad_hook)\n",
        "\n",
        "# ''' Targeted triggers '''\n",
        "print('TARGETED TRIGGERS')\n",
        "dataset_label_filter = \"pos\"\n",
        "targeted_dev_data = []\n",
        "for instance in train_data:\n",
        "    if instance.label == dataset_label_filter:\n",
        "        targeted_dev_data.append(instance)\n",
        "\n",
        "target_data = tt.data.Dataset(targeted_dev_data, fields=[('text', c_text), ('label', c_label)])\n",
        "target_iter = tt.data.Iterator(target_data, batch_size=batch_size, shuffle = True,\n",
        "                                sort_key=lambda x: x.text[1])\n",
        "\n",
        "# ''' General Triggers '''\n",
        "# print(\"GENERAL TRIGGERS\")\n",
        "# target_iter = test_iterator\n",
        "\n",
        "\n",
        "''' Sentiment words '''\n",
        "# senti_words = []\n",
        "# f = open(\"positive-words.txt\", \"r\", encoding = \"ISO-8859-1\")\n",
        "# senti_words += [line.rstrip(\"\\n\") for line in f.readlines() if line!='\\n' and line[0] != ';']\n",
        "# f = open(\"negative-words.txt\", \"r\", encoding = \"ISO-8859-1\")\n",
        "# senti_words += [line.rstrip(\"\\n\") for line in f.readlines() if line!='\\n' and line[0] != ';']\n",
        "\n",
        "# senti_word_id = [c_text.vocab.stoi[word] for word in senti_words]\n",
        "\n",
        "\n",
        "# Trigger tokens\n",
        "num_trigger_tokens = 3\n",
        "trigger_token_ids = [c_text.vocab.stoi[\"the\"]] * num_trigger_tokens\n",
        "\n",
        "TRIGGER_EPOCHS = 5\n",
        "for epoch in range(TRIGGER_EPOCHS):\n",
        "    # Get Accuracy\n",
        "    print_string = \"\"\n",
        "    for idx in trigger_token_ids:\n",
        "        print_string = print_string + c_text.vocab.itos[idx] + ', '\n",
        "    print(\"Current Triggers: \" + print_string + \" : \" + str(get_accuracy(model, target_iter, criterion,trigger_token_ids, device).item()))\n",
        "\n",
        "    # Get Average grad\n",
        "    ###\n",
        "    i = 0\n",
        "    for batch in target_iter:\n",
        "        text = batch.text\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Reset extracted_grads as in next step we get element at index 0\n",
        "\n",
        "        # RNN needs to be in train() to calculate gradient\n",
        "        # Hence, disable dropouts manually\n",
        "        model.train()\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, nn.Dropout):\n",
        "                module.p = 0\n",
        "    \n",
        "            elif isinstance(module, nn.LSTM):\n",
        "                module.dropout = 0\n",
        "    \n",
        "            elif isinstance(module, nn.GRU):\n",
        "                module.dropout = 0\n",
        "\n",
        "        # Append trigger tokens\n",
        "        trigger_sequence_tensor = torch.LongTensor(copy.deepcopy(trigger_token_ids)) \n",
        "        trigger_sequence_tensor = trigger_sequence_tensor.repeat(batch.label.shape[0], 1) # batch_size is global\n",
        "        b_text = torch.cat((trigger_sequence_tensor, text.cpu()), dim=1)\n",
        "        \n",
        "\n",
        "        y_pred = model(b_text.to(device)).squeeze(1)\n",
        "        loss = criterion(y_pred, batch.label.to(device))\n",
        "\n",
        "        extracted_grads = []\n",
        "        loss.backward()\n",
        "    \n",
        "        data_grad = extracted_grads[0]\n",
        "        averaged_grad = torch.sum(data_grad, dim=0)\n",
        "        # Get gradient of trigger tokens only\n",
        "        averaged_grad = averaged_grad[0:len(trigger_token_ids)]\n",
        "\n",
        "        # print(averaged_grad.sum())\n",
        "\n",
        "        st = time.time()\n",
        "        cand_trigger_token_ids = hotflip_attack(averaged_grad,\n",
        "                                                        model.embedding.weight,\n",
        "                                                        trigger_token_ids,\n",
        "                                                        num_candidates=40,\n",
        "                                                        increase_loss=True)\n",
        "        trigger_token_ids = get_best_candidates(model,\n",
        "                                                    batch,\n",
        "                                                    criterion,\n",
        "                                                    trigger_token_ids,\n",
        "                                                    cand_trigger_token_ids,\n",
        "                                                    device)\n",
        "        et = time.time()\n",
        "\n",
        "        # if i == 5:\n",
        "        #     break\n",
        "        # else:\n",
        "        #     i += 1\n",
        "    # print(\"Time spent: \", time_min_sec(st, et))\n",
        "\n",
        "print_string = \"\"\n",
        "for idx in trigger_token_ids:\n",
        "    print_string = print_string + c_text.vocab.itos[idx] + ', '\n",
        "print(\"Current Triggers: \" + print_string + \" : \" + str(get_accuracy(model, target_iter, criterion, trigger_token_ids, device).item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKN0-CAYgrT0",
        "colab_type": "text"
      },
      "source": [
        "# Test User input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PheeZ1yrRAmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def predict_senti(model, sentence):\n",
        "    model.eval()\n",
        "\n",
        "    tokenized = [token.text for token in nlp.tokenizer(sentence.lower())]\n",
        "    indexed = [c_text.vocab.stoi[t] for t in tokenized]\n",
        "\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "\n",
        "    y_pred = torch.sigmoid(model(tensor))\n",
        "\n",
        "    return torch.round(y_pred).item()\n",
        "\n",
        "def predict_triggered_senti(model, sentence, trigger_tokens):\n",
        "    model.eval()\n",
        "\n",
        "    tokenized = trigger_tokens + [token.text for token in nlp.tokenizer(sentence.lower())]\n",
        "    indexed = [c_text.vocab.stoi[t] for t in tokenized]\n",
        "\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "\n",
        "    y_pred = torch.sigmoid(model(tensor))\n",
        "    return torch.round(y_pred).item()\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "def html_render(x_orig, x_adv, trig_len):\n",
        "    x_orig_words = x_orig.split(' ')\n",
        "    x_adv_words = x_adv.split(' ')\n",
        "    orig_html = []\n",
        "    adv_html = []\n",
        "    for i in range(len(x_orig_words)):\n",
        "        orig_html.append(x_orig_words[i])\n",
        "\n",
        "    for i in range(len(x_adv_words)):\n",
        "        if i < trig_len:\n",
        "            adv_html.append(format(\"<b style='color:red'>%s</b>\" %x_adv_words[i]))\n",
        "        else:\n",
        "            adv_html.append(x_adv_words[i])\n",
        "    \n",
        "    orig_html = ' '.join(orig_html)\n",
        "    adv_html = ' '.join(adv_html)\n",
        "    return orig_html, adv_html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F73S87svg8fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [\n",
        "    'This movies is alright',\n",
        "    'Pathetic hero. Anyways, the movie is good',\n",
        "    'Wasted my money on this film',\n",
        "    'The movie is not good, its amazing',\n",
        "    'The movie is not good',\n",
        "    'The movie is bad',\n",
        "    'Read the book, forget the movie!',\n",
        "    \"This is a good film. This is very funny. Yet after this film there were no good Ernest films!\",\n",
        "]\n",
        "\n",
        "sentences = [\n",
        "    \"This is a good film. This is very funny. Yet after this film there were no good Ernest films!\",\n",
        "    \"Visually imaginative, thematically instructive and thoroughly delightful, it takes us on a roller-coaster ride\",\n",
        "    \"As surreal as a dream and as detailed as a photograph, as visually dexterous as it is at times imaginatively overwhelming\",\n",
        "    'Wasted my money on this film',\n",
        "    'Read the book, forget the movie!',\n",
        "    'The movie is not good, its amazing',\n",
        "    'What a terrible film!',\n",
        "]\n",
        "\n",
        "trigger_tokens = ['unisol', 'unisol', 'rosenlski']\n",
        "\n",
        "for sentence in sentences:\n",
        "    orig, adv = html_render(sentence, \" \".join(trigger_tokens) + \" \" + sentence, len(trigger_tokens))\n",
        "\n",
        "    print(\"----------- Original Sentence ----------\")\n",
        "    display(HTML(orig))\n",
        "\n",
        "    print(\"----------- Adversarial Sentence ----------\")\n",
        "    display(HTML(adv))\n",
        "    print(\"-\"*100)\n",
        "    print(\"positive\" if predict_senti(model, sentence) > 0 else \"negative\", end=\" -> \")\n",
        "    print(\"positive\" if predict_triggered_senti(model, sentence, trigger_tokens) > 0 else \"negative\")\n",
        "\n",
        "    print(\"=\"*100, end=\"\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XolYjaxjwDfT",
        "colab_type": "text"
      },
      "source": [
        "## Test Accuracy after triggers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmHWiq58g9Og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = []\n",
        "orig = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_iterator:\n",
        "        text = batch.text\n",
        "        trigger_sequence_tensor = torch.LongTensor(copy.deepcopy(trigger_token_ids)) \n",
        "        trigger_sequence_tensor = trigger_sequence_tensor.repeat(batch.label.shape[0], 1) # batch_size is global\n",
        "        b_text = torch.cat((trigger_sequence_tensor, text.cpu()), dim=1)\n",
        "        \n",
        "\n",
        "        y_pred = model(b_text.to(device)).squeeze(1)\n",
        "        y_pred = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "        pred.append(y_pred.cpu())\n",
        "        orig.append(batch.label.cpu())\n",
        "        \n",
        "    pred = torch.cat(pred, dim=0)\n",
        "    orig = torch.cat(orig, dim=0)\n",
        "def plot_confusion_matrix(pred_labels, labels):\n",
        "    \n",
        "    fig = plt.figure(figsize = (5,5));\n",
        "    ax = fig.add_subplot(1, 1, 1);\n",
        "    cm = confusion_matrix(labels, pred_labels);\n",
        "    cm = ConfusionMatrixDisplay(cm, range(2));\n",
        "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
        "plot_confusion_matrix(pred, orig)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}